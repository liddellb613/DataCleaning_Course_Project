#read.csv()
print(tf)
}
}
str()
str(str)
str(lm)
install.packages(c("blob", "broom", "crayon", "fansi", "formatR", "gert", "haven", "knitr", "magrittr", "processx", "RColorBrewer", "Rcpp", "readxl", "rprojroot", "RSQLite", "sass", "scales", "testthat", "tinytex", "tzdb", "vctrs", "waldo"))
library(XML)
fileUrl <- "http://www.w3schools.com/xml/simple.xml"
doc <- xmlTreeParse(fileUrl, useInternalNodes = TRUE)
doc <- xmlTreeParse(fileUrl)
fileUrl <- "https://www.w3schools.com/xml/simple.xml"
doc <- xmlTreeParse(fileUrl, useInternalNodes = TRUE)
doc <- xmlTreeParse(fileUrl, useInternal = TRUE)
doc
doc <- xmlParse(fileUrl, useInternal = TRUE)
head(fileUrl)
version()
version
doc <- xmlParse(fileUrl, useInternal = TRUE)
library(xml2)
doc <- xml_read(fileUrl, useInternal = TRUE)
doc <- read_xml(fileUrl, useInternal = TRUE)
class(doc)
rootNode <- xmlRoot(doc)
rootNode <- xml_root(doc)
xmlName(rootNode)
xml_name(rootNode)
names(rootNode)
rootNode[[1]]
doc <- xmlParse(fileUrl, useInternal = TRUE)
install.packages(c("checkmate", "matrixStats", "uuid"))
version
install.packages(c("checkmate", "uuid"))
rootNode[[1]]
xml_name(rootNode)
?names
doc <- xmlParse(fileUrl, useInternal = TRUE)
doc <- xmlTreeParse(fileUrl, useInternal = TRUE)
library(httr)
doc <- xmlTreeParse(fileUrl, useInternal = TRUE)
r <= GET(fileUrl)
r <- GET(fileUrl)
r
doc <- xmlTreeParse(r, useInternal = TRUE)
doc
rootNode <- xmlRoot(doc)
xmlName(rootNode)
names(rootNode)
rootNode[[1]]
rootNode[[1]][[1]]
rootNode[[1]][[2]]
rootNode[[1]][[3]]
xmlSApply(rootNode, xmlValue)
xmlSApply(rootNode, "//name", xmlValue)
xpathSApply(rootNode, "//name", xmlValue)
xpathSApply(rootNode, "//price", xmlValue)
library(data.table)
DF = data.frame(x=rnorm(9), y=rep(c("a","b","c"), each=3), z=rnorm(9))
head(DF,3)
DF = data.table(x=rnorm(9), y=rep(c("a","b","c"), each=3), z=rnorm(9))
head(DF,3)
tables()
DT[2,]
DF[2,]
DF[DF$y=="a",]
DF[c(2,3)]
DF[,c(2,3)]
class(DF)
str(DF)
DF[,list(mean(x), sum(z))]
DF[,table(y)]
DF[,w:=z^2]
DF
swirl()
library(swirl)
swirl()
swirl()
install_course("Getting and Cleaning Data")
swirl()
ls()
swirl::install_course("Getting and Cleaning Data")
swirl()
swirl()
mydf <- read.csv(path2csv, stringsAsFactors = FALSE)
dim(mydf)
head(mydf)
library(dplyr)
packageVersion("dplyr")
cran <- tbl_df(mydf)
rm("mydf")
cran
?select
select(cran, ip_id, package,country)
5:20
select(cran, r_arch:country)
select(cran, country:r_arch)
print(cran)
cran
select(cran, -time)
select(cran, -x:size)
-5:20
-(5:20)
select(cran, -(5:20))
select(cran, -(x:size))
select(cran, -(X:size))
filter(cran, package=="swirl")
filter(cran, r_version == "3.1.1", country == "US")
?Comparison
filter(cran, r_version <= "3.0.2", country == "IN")
filter(cran, country == "IN" | country == "US")
filter(cran, r_os == "linux-gnu" & size > 100500)
filter(cran, r_os == "linux-gnu",size > 100500)
is.na(c(3, 5, NA, 10))
!is.na(c(3, 5, NA, 10))
filter(cran, !is_na(r_version))
filter(cran, !is_na(c(r_version))
)
filter(cran, !(is_na(r_version))
)
filter(cran, is_na(r_version))
filter(cran, !is.na(r_version))
cran2 <- select(cran,size:ip_id)
arrange(cran2, ip_id)
arrange(cran2, desc(ip_id)
)
arrange(cran2, package, ip_id)
arrange(cran2, country, desc(r_version), ip_id)
cran3 <- select(cran, ip_id, package, size)
cran3
mutate(cran3, size_mb = size / 2^20)
mutate(cran3, size_mb = size / 2^20, size_gb = size_mb / 2^10)
mutate(cran3, correct_size = size * 2^3)
mutate(cran3, correct_size = size + 1000)
summarize(cran, avg_bytes = mean(size))
swirl()
swirl()
library(dplyr)
cran <- tbl_df(mydf)
rm("mydf")
cran
?group_by
by_package <- grou_by(cran, package)
swirl()
library(swirl)
swirl()
swirl()
library(dplyr)
cran <- tbl_df(mydf)
rm("mydf")
cran
?group_by
by_package <- group_by(cran, package)
by_package
summarize(by_package, mean(size))
?n
?n_distinct
submit()
pack_sum
quantile(packsum$count, probs = 0.99)
quantile(pack_sum$count, probs = 0.99)
top_counts <- filter(pack_sum, count > 679)
top_counts
view(top_counts)
View(top_counts)
top_counts_sorted <- arrange(top_counts, desc(count))
view(top_counts_sorted)
View(top_counts_sorted)
quantile(pack_sum$unique, probs = 0.99)
top_unique <- filter(pack_sum, unique > 465)
View(top_unique)
top_unique_sorted <- arrange(top_unique, desc(unique()))
top_unique_sorted <- arrange(top_unique, desc(unique))
View(top_unique_sorted)
submit("summarize2.R")
submit()
submit()
submit()
View(result3)
submit()
submit
submit()
submit()
submit()
submit()
submit()
submit
submit()
library(reshape2)
head(mtcars)
head(InsectSprays)
tail(InsectSprays)
spIns = split(InsectSprays$count, InsectSprays$spray)
spIns
str(spIns)
sprCount = lapply(spIns, sum)
sprCount
unlist(sprCount)
str(unlist(sprCount))
sapply(spIns, sum)
library(dplyr)
library(plyr)
detach("package:plyr", unload = TRUE)
library(plyr)
detach("package:dplyr", unload = TRUE)
library(dplyr)
detach("package:dplyr", unload = TRUE)
ddply(InsectSprays,.(spray), summarize, sum=sum(count))
ddply(InsectSprays,.(spray), summarize, sum=ave(count, FUN=sum))
install.packages(c("BiocManager", "cli", "dplyr", "ggplot2", "httr", "knitr", "openssl", "rmarkdown", "roxygen2", "RSQLite", "testthat", "tibble", "tinytex", "xfun"))
install.packages(c("openssl", "usethis"))
library(swirl)
swirl()
Sys.getlocale("LC_TIME")
library(lubridate)
help(package="lubridate")
help(package=lubridate)
this_day <- today()
this_day
year(this_day)
wday(this_day)
wday(this_day, label = T)
wday(this_day, label = TRUE)
now()
this_moment <- now()
this_moment
minute(this_moment)
ymd("1989-05-17")
my_date <- ymd("1989-05-17")
my_date
class(my_date)
ymd("1989 May 17")
mdy("March 12, 1975")
dmy("25081985")
dmy(25081985)
ymd("192012")
ymd("1920-1-2")
dt1
ymd_hms(dt1)
hms("03:22:14")
dt2
ymd(dt2)
update(this_moment, hours =8, minutes=34, seconds=55)
this_moment
this_moment <- update(this_moment, hour=19, minutes=4)
update(this_moment, hour=19, minutes=4)
this_moment <- update(this_moment, hour=10, minutes=16, seconds=-)
this_moment <- update(this_moment, hour=10, minutes=16, seconds=0)
this_moment <- update(this_moment, hours=10, minutes=16, seconds=0)
this_moment
skip()
skip()
skip()
skip()
skip()
skip()
skip()
skip()
skip()
skip()
skip()
skip()
skip()
skip()
skip()
skip()
setwd("~/CourseraRProjects/DataCleaning_Course_Project")
library(tidyverse)
if(!file.exists("./data")) {dir.create("./data")}
fileURL <- "https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"
download.file(fileURL, destfile = "./data/healthdata.zip", method = "curl")
unzip("./data/healthdata.zip", exdir = "../..")
subjecttestURL <- "../UCI HAR Dataset/test/subject_test.txt"
subjecttrainURL <- "../UCI HAR Dataset/train/subject_train.txt"
obstestURL <- "../UCI HAR Dataset/test/X_test.txt"
obstrainURL <- "../UCI HAR Dataset/train/X_train.txt"
acttestURL <- "../UCI HAR Dataset/test/y_test.txt"
acttrainURL <- "../UCI HAR Dataset/train/y_train.txt"
featuresURL <- "../UCI HAR Dataset/features.txt"
actnamesURL <- "../UCI HAR Dataset/activity_labels.txt"
train.subjects <- read.table(subjecttrainURL)
test.subjects <- read.table(subjecttestURL)
train.vals <- read.table(obstrainURL)
test.vals <- read.table(obstestURL)
train.act <- read.table(acttrainURL)
test.act <- read.table(acttestURL)
features <- read.table(featuresURL)
act_names <- read.table(actnamesURL)
# Rename columns of single variable data sets (subjects and activities).
# Doing this early so as to not have to rename columns in the format 'V1...1'
# later after the columns are bound.
train.subjects <- train.subjects %>% rename(subject = V1)
train.act <- train.act %>% rename(activity = V1)
test.subjects <- test.subjects %>% rename(subject = V1)
test.act <- test.act %>% rename(activity = V1)
features <- features %>% rename(value_no = V1, value_name = V2)
act.names <- act.names %>% rename(act_no = V1, act_desc = V2)
# setup new and old column vectors for the feature data sets
# only capture the column names that have mean() and std() at the
# end of the feature name. Other values excluded include meanFreq()
# values which are a weighted average of frequency components rather
# than the raw mean.
# Find the column positions with the mean() and std() values
col_numbers <- grep("-mean\\(\\)|-std\\(\\)", features$value_name)
# Build the list of old column names, this allow for flexibility if columns
# are added or removed in the future
col_names_old <- str_c("V",col_numbers)
# Build the list of selected new column names from the features.txt file
col_names_new <- features$value_name[col_numbers]
# Select only the columns needed from the features data sets
train.vals <- train.vals %>% select(all_of(col_names_old))
test.vals <- test.vals %>% select(all_of(col_names_old))
# Rename the required features columns
colnames(train.vals) <- col_names_new
colnames(test.vals) <- col_names_new
# Combine the subject, activity, and features data sets by column into a single
# data set
train.obs <- bind_cols(train.subjects, train.act, train.vals)
test.obs <- bind_cols(test.subjects, test.act, test.vals)
# Merge the test and train tables by row into a tidy observations data set
tidy.obs <- bind_rows(train.obs, test.obs)
# Add descriptive activity names
tidy.obs <- tidy.obs %>% mutate(activity = act.names$act_desc[activity])
# Group tidy observations by activity and subject
# Summarise for the average of each activity and subject
output_data <- tidy.obs %>% group_by(activity, subject) %>% summarise_all(mean)
#output_data <- tidy.obs %>% group_by(activity, subject) %>% summarise_if(is.numeric, mean)
write.table(output_data, "./data/run_analysis_out.txt",row.names = FALSE )
train.subjects <- read.table(subjecttrainURL)
test.subjects <- read.table(subjecttestURL)
train.vals <- read.table(obstrainURL)
test.vals <- read.table(obstestURL)
train.act <- read.table(acttrainURL)
test.act <- read.table(acttestURL)
features <- read.table(featuresURL)
act.names <- read.table(actnamesURL)
# Rename columns of single variable data sets (subjects and activities).
# Doing this early so as to not have to rename columns in the format 'V1...1'
# later after the columns are bound.
train.subjects <- train.subjects %>% rename(subject = V1)
train.act <- train.act %>% rename(activity = V1)
test.subjects <- test.subjects %>% rename(subject = V1)
test.act <- test.act %>% rename(activity = V1)
features <- features %>% rename(value_no = V1, value_name = V2)
act.names <- act.names %>% rename(act_no = V1, act_desc = V2)
# setup new and old column vectors for the feature data sets
# only capture the column names that have mean() and std() at the
# end of the feature name. Other values excluded include meanFreq()
# values which are a weighted average of frequency components rather
# than the raw mean.
# Find the column positions with the mean() and std() values
col_numbers <- grep("-mean\\(\\)|-std\\(\\)", features$value_name)
# Build the list of old column names, this allow for flexibility if columns
# are added or removed in the future
col_names_old <- str_c("V",col_numbers)
# Build the list of selected new column names from the features.txt file
col_names_new <- features$value_name[col_numbers]
# Select only the columns needed from the features data sets
train.vals <- train.vals %>% select(all_of(col_names_old))
test.vals <- test.vals %>% select(all_of(col_names_old))
# Rename the required features columns
colnames(train.vals) <- col_names_new
colnames(test.vals) <- col_names_new
# Combine the subject, activity, and features data sets by column into a single
# data set
train.obs <- bind_cols(train.subjects, train.act, train.vals)
test.obs <- bind_cols(test.subjects, test.act, test.vals)
# Merge the test and train tables by row into a tidy observations data set
tidy.obs <- bind_rows(train.obs, test.obs)
# Add descriptive activity names
tidy.obs <- tidy.obs %>% mutate(activity = act.names$act_desc[activity])
# Group tidy observations by activity and subject
# Summarise for the average of each activity and subject
output_data <- tidy.obs %>% group_by(activity, subject) %>% summarise_all(mean)
#output_data <- tidy.obs %>% group_by(activity, subject) %>% summarise_if(is.numeric, mean)
write.table(output_data, "./data/run_analysis_out.txt",row.names = FALSE )
view(col_names_new)
col_numbers <- grep("mean|std", features$value_name)
#col_numbers <- grep("-mean\\(\\)|-std\\(\\)", features$value_name)
# Build the list of old column names, this allow for flexibility if columns
# are added or removed in the future
col_names_old <- str_c("V",col_numbers)
# Build the list of selected new column names from the features.txt file
col_names_new <- features$value_name[col_numbers]
# Select only the columns needed from the features data sets
train.vals <- train.vals %>% select(all_of(col_names_old))
test.vals <- test.vals %>% select(all_of(col_names_old))
# Rename the required features columns
colnames(train.vals) <- col_names_new
colnames(test.vals) <- col_names_new
# Combine the subject, activity, and features data sets by column into a single
# data set
train.obs <- bind_cols(train.subjects, train.act, train.vals)
test.obs <- bind_cols(test.subjects, test.act, test.vals)
# Merge the test and train tables by row into a tidy observations data set
tidy.obs <- bind_rows(train.obs, test.obs)
# Add descriptive activity names
tidy.obs <- tidy.obs %>% mutate(activity = act.names$act_desc[activity])
# Group tidy observations by activity and subject
# Summarise for the average of each activity and subject
output_data <- tidy.obs %>% group_by(activity, subject) %>% summarise_all(mean)
#output_data <- tidy.obs %>% group_by(activity, subject) %>% summarise_if(is.numeric, mean)
write.table(output_data, "./data/run_analysis_out.txt",row.names = FALSE )
train.subjects <- read.table(subjecttrainURL)
test.subjects <- read.table(subjecttestURL)
train.vals <- read.table(obstrainURL)
test.vals <- read.table(obstestURL)
train.act <- read.table(acttrainURL)
test.act <- read.table(acttestURL)
features <- read.table(featuresURL)
act.names <- read.table(actnamesURL)
# Rename columns of single variable data sets (subjects and activities).
# Doing this early so as to not have to rename columns in the format 'V1...1'
# later after the columns are bound.
train.subjects <- train.subjects %>% rename(subject = V1)
train.act <- train.act %>% rename(activity = V1)
test.subjects <- test.subjects %>% rename(subject = V1)
test.act <- test.act %>% rename(activity = V1)
features <- features %>% rename(value_no = V1, value_name = V2)
act.names <- act.names %>% rename(act_no = V1, act_desc = V2)
# setup new and old column vectors for the feature data sets
# only capture the column names that have mean() and std() at the
# end of the feature name. Other values excluded include meanFreq()
# values which are a weighted average of frequency components rather
# than the raw mean.
# Find the column positions with the mean() and std() values
col_numbers <- grep("mean|std", features$value_name)
#col_numbers <- grep("-mean\\(\\)|-std\\(\\)", features$value_name)
# Build the list of old column names, this allow for flexibility if columns
# are added or removed in the future
col_names_old <- str_c("V",col_numbers)
# Build the list of selected new column names from the features.txt file
col_names_new <- features$value_name[col_numbers]
# Select only the columns needed from the features data sets
train.vals <- train.vals %>% select(all_of(col_names_old))
test.vals <- test.vals %>% select(all_of(col_names_old))
# Rename the required features columns
colnames(train.vals) <- col_names_new
colnames(test.vals) <- col_names_new
# Combine the subject, activity, and features data sets by column into a single
# data set
train.obs <- bind_cols(train.subjects, train.act, train.vals)
test.obs <- bind_cols(test.subjects, test.act, test.vals)
# Merge the test and train tables by row into a tidy observations data set
tidy.obs <- bind_rows(train.obs, test.obs)
# Add descriptive activity names
tidy.obs <- tidy.obs %>% mutate(activity = act.names$act_desc[activity])
# Group tidy observations by activity and subject
# Summarise for the average of each activity and subject
output_data <- tidy.obs %>% group_by(activity, subject) %>% summarise_all(mean)
#output_data <- tidy.obs %>% group_by(activity, subject) %>% summarise_if(is.numeric, mean)
write.table(output_data, "./data/run_analysis_out.txt",row.names = FALSE )
subjecttestURL <- "../UCI HAR Dataset/test/subject_test.txt"
subjecttrainURL <- "../UCI HAR Dataset/train/subject_train.txt"
obstestURL <- "../UCI HAR Dataset/test/X_test.txt"
obstrainURL <- "../UCI HAR Dataset/train/X_train.txt"
acttestURL <- "../UCI HAR Dataset/test/y_test.txt"
acttrainURL <- "../UCI HAR Dataset/train/y_train.txt"
featuresURL <- "../UCI HAR Dataset/features.txt"
actnamesURL <- "../UCI HAR Dataset/activity_labels.txt"
train.subjects <- read.table(subjecttrainURL)
test.subjects <- read.table(subjecttestURL)
train.vals <- read.table(obstrainURL)
test.vals <- read.table(obstestURL)
train.act <- read.table(acttrainURL)
test.act <- read.table(acttestURL)
features <- read.table(featuresURL)
act.names <- read.table(actnamesURL)
# Rename columns of single variable data sets (subjects and activities).
# Doing this early so as to not have to rename columns in the format 'V1...1'
# later after the columns are bound.
train.subjects <- train.subjects %>% rename(subject = V1)
train.act <- train.act %>% rename(activity = V1)
test.subjects <- test.subjects %>% rename(subject = V1)
test.act <- test.act %>% rename(activity = V1)
features <- features %>% rename(value_no = V1, value_name = V2)
act.names <- act.names %>% rename(act_no = V1, act_desc = V2)
# setup new and old column vectors for the feature data sets
# only capture the column names that have mean() and std() at the
# end of the feature name. Other values excluded include meanFreq()
# values which are a weighted average of frequency components rather
# than the raw mean.
# Find the column positions with the mean() and std() values
col_numbers <- grep("mean|std", features$value_name)
#col_numbers <- grep("-mean\\(\\)|-std\\(\\)", features$value_name)
# Build the list of old column names, this allow for flexibility if columns
# are added or removed in the future
col_names_old <- str_c("V",col_numbers)
# Build the list of selected new column names from the features.txt file
col_names_new <- features$value_name[col_numbers]
# Select only the columns needed from the features data sets
train.vals <- train.vals %>% select(all_of(col_names_old))
test.vals <- test.vals %>% select(all_of(col_names_old))
# Rename the required features columns
colnames(train.vals) <- col_names_new
colnames(test.vals) <- col_names_new
# Combine the subject, activity, and features data sets by column into a single
# data set
train.obs <- bind_cols(train.subjects, train.act, train.vals)
test.obs <- bind_cols(test.subjects, test.act, test.vals)
# Merge the test and train tables by row into a tidy observations data set
tidy.obs <- bind_rows(train.obs, test.obs)
# Add descriptive activity names
tidy.obs <- tidy.obs %>% mutate(activity = act.names$act_desc[activity])
# Group tidy observations by activity and subject
# Summarise for the average of each activity and subject
output_data <- tidy.obs %>% group_by(activity, subject) %>% summarise_all(mean)
#output_data <- tidy.obs %>% group_by(activity, subject) %>% summarise_if(is.numeric, mean)
write.table(output_data, "./data/run_analysis_out.txt",row.names = FALSE )
View(col_names_new)
view(col_names_new)
